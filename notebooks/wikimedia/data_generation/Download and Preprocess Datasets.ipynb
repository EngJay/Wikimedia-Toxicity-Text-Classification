{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext autotime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from db_utils import query_hive_ssh\n",
    "import re\n",
    "import copy\n",
    "from diff_utils import *\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.4 ms\n"
     ]
    }
   ],
   "source": [
    "cols =  ['rev_comment', 'insertion', 'insert_only', 'rev_id', 'page_id', 'page_title', 'rev_timestamp', 'user_id', 'user_text']\n",
    "nss = ['user', 'article']\n",
    "datasets = []\n",
    "\n",
    "for ns in nss:\n",
    "    \n",
    "    \n",
    "    d1 = {\n",
    "        'table':'blocked_talk_diff_no_admin',\n",
    "        'partition':'ns=%s' % ns, \n",
    "        'ns': ns,\n",
    "        'name': 'all_blocked_user',\n",
    "        'cols' : cols\n",
    "        }\n",
    "    datasets.append(d1)\n",
    "    \n",
    "    \n",
    "    d2 = {\n",
    "        'table':'%s_talk_diff_no_admin_sample' % ns,\n",
    "        'partition':'', \n",
    "        'ns': ns,\n",
    "        'name': 'talk_diff_no_admin_sample',\n",
    "        'cols' : cols,\n",
    "        }\n",
    "    datasets.append(d1)\n",
    "    \n",
    "    d3 = {\n",
    "        'table':'talk_diff_no_admin',\n",
    "        'partition':'ns=%s/year=2015' % ns, \n",
    "        'ns': ns,\n",
    "        'name': 'talk_diff_no_admin_2015',\n",
    "        'cols' : cols,\n",
    "        }\n",
    "    datasets.append(d3)\n",
    "        \n",
    "        \n",
    "cols2 = ['rev_comment', 'insertion', 'insert_only', 'rev_id', 'page_id', 'page_title', 'rev_timestamp', 'user_id', 'user_text', 'bot', 'admin']           \n",
    "datasets = []\n",
    "\n",
    "for year in range(2001, 2016):\n",
    "    for ns in nss:    \n",
    "        d = {\n",
    "            'table':'talk_diff',\n",
    "            'partition':'ns=%s/year=%d' % (ns, year), \n",
    "            'ns': '%s' % ns,\n",
    "            'name': 'talk_diff_%d' % year,\n",
    "            'cols' : cols2\n",
    "            }\n",
    "        datasets.append(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.76 ms\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    d['hdfs_path'] = '/user/hive/warehouse/enwiki.db/%(table)s/%(partition)s' % d\n",
    "    d['stat2_path'] = '/home/ellery/detox/data/samples/%(ns)s/raw/%(name)s' % d\n",
    "    d['raw_local_path'] = '/Users/ellerywulczyn/detox/data/samples/%(ns)s/raw/%(name)s/' % d\n",
    "    d['clean_local_path'] = '/Users/ellerywulczyn/detox/data/samples/%(ns)s/clean/%(name)s/' % d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.97 ms\n"
     ]
    }
   ],
   "source": [
    "def transfer_partition(d, dry = False):\n",
    "    \n",
    "    if not dry:\n",
    "        # transfer from HDFS to stat2\n",
    "        cmd = \"ssh stat1002.eqiad.wmnet 'rm -rf %s'\" % d['stat2_path']\n",
    "        print(os.system(cmd))\n",
    "        cmd = \"ssh stat1002.eqiad.wmnet 'hadoop fs -copyToLocal %s %s '\" % (d['hdfs_path'], d['stat2_path'])\n",
    "        print(os.system(cmd))\n",
    "        #transfer from stat2 to local\n",
    "        cmd = 'rm -rf %s' % d['raw_local_path']\n",
    "        print(os.system(cmd))\n",
    "        cmd = 'rsync -avz  stat1002.eqiad.wmnet:%s/* %s' % (d['stat2_path'], d['raw_local_path'])\n",
    "        os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "time: 5h 59min 59s\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    local_path = transfer_partition(d, dry = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2001/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2001/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2002/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2002/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2003/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2003/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2004/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2004/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2005/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2005/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2006/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2006/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2007/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2007/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2008/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2008/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2009/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2009/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2010/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2010/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2011/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2011/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2012/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2012/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2013/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2013/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2014/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2014/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2015/',\n",
       " '/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2015/']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.76 ms\n"
     ]
    }
   ],
   "source": [
    "[d['raw_local_path'] for d in datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cleaning and Filtering__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.1 ms\n"
     ]
    }
   ],
   "source": [
    "def cf_helper(path, cols, k = 5):\n",
    "    df = pd.read_csv(path, sep = '\\t', quoting = 3, encoding = 'utf-8', header = None, usecols=range(len(cols)))\n",
    "    if df.shape[0] ==0:\n",
    "        return pd.DataFrame(columns = cols)\n",
    "    if df.shape[1] != len(cols):\n",
    "        print(path)\n",
    "        print(df.shape)\n",
    "        return pd.DataFrame(columns = cols)\n",
    "    df.columns = cols\n",
    "    df = df.assign(key = lambda x: np.random.randint(0, high=5*k, size=x.shape[0]))\n",
    "    dfs = [e[1] for e in df.groupby('key')]\n",
    "    p = mp.Pool(k)\n",
    "    dfs = p.map(clean_and_filter, dfs)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.8 ms\n"
     ]
    }
   ],
   "source": [
    "def clean_and_filter_parallel(d, k = 7):\n",
    "    \n",
    "    indir = d['raw_local_path']\n",
    "    outdir = d['clean_local_path']\n",
    "    os.system(\"rm -rf %s\" % outdir)\n",
    "    os.system(\"mkdir %s\" % outdir)\n",
    "    cols = d['cols']\n",
    "    files = []\n",
    "    for root, dirnames, filenames in os.walk(indir):\n",
    "        for filename in filenames:\n",
    "            if '_0' in filename:\n",
    "                files.append(os.path.join(root, filename))\n",
    "                \n",
    "    for i, file in enumerate(files):            \n",
    "        df = cf_helper(file, cols, k = k) \n",
    "        del df['key']\n",
    "        df.to_csv(os.path.join(outdir, \"chunk_%d.tsv\" % i), sep = '\\t', index = False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2001/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2001/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2002/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2002/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2003/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2003/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2004/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2004/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2005/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2005/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2006/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2006/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2007/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2007/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2008/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2008/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2009/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2009/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2010/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2010/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2011/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2011/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2012/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2012/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2013/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2013/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2014/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2014/\n",
      "/Users/ellerywulczyn/detox/data/samples/user/raw/talk_diff_2015/\n",
      "/Users/ellerywulczyn/detox/data/samples/article/raw/talk_diff_2015/\n",
      "time: 4h 2min 57s\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    print(d['raw_local_path'])\n",
    "    clean_and_filter_parallel(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download `block_events` and `blocked_users`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "      *\n",
    "FROM\n",
    "    enwiki.block_events\n",
    "\"\"\"\n",
    "\n",
    "block_events_df = query_hive_ssh(query, '../../data/block_events.tsv', priority = True, quoting=3, delete=False)\n",
    "block_events_df.columns = [c.split('.')[1] for c in block_events_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "      *\n",
    "FROM\n",
    "    enwiki.blocked_user\n",
    "\"\"\"\n",
    "\n",
    "blocked_user_df = query_hive_ssh(query, '../../data/blocked_user.tsv', priority = True, quoting=3, delete=False)\n",
    "blocked_user_df.columns = [c.split('.')[1] for c in blocked_user_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download NPA warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "      *\n",
    "FROM\n",
    "    enwiki.npa_warnings\n",
    "\"\"\"\n",
    "\n",
    "npa_warnings_df = query_hive_ssh(query, '../../data/npa_warnings.tsv', priority = True, quoting=3, delete=False)\n",
    "npa_warnings_df.columns = [c.split('.')[1] for c in npa_warnings_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Long term Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    user_text,\n",
    "    COUNT(*) AS num_days\n",
    "FROM\n",
    "    (SELECT\n",
    "        user_text,\n",
    "        day\n",
    "    FROM\n",
    "        (SELECT \n",
    "            rev_user_text AS user_text,\n",
    "            SUBSTR(rev_timestamp,0,8) AS day\n",
    "        FROM\n",
    "            enwiki.revision\n",
    "        WHERE\n",
    "            rev_user != 0\n",
    "            AND rev_timestamp <= '2015-01-01'\n",
    "        ) a\n",
    "    GROUP BY\n",
    "        user_text,\n",
    "        day ) b\n",
    "GROUP BY\n",
    "    user_text\n",
    "HAVING\n",
    "    COUNT(*) > 7 \n",
    "\"\"\"\n",
    "\n",
    "long_term_users_df = query_hive_ssh(query, '../../data/long_term_users.tsv', priority = True, quoting=3, delete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Annotate users by gender\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    user_id,\n",
    "    user_name as user_text,\n",
    "    up_value as gender\n",
    "FROM\n",
    "    enwiki.user_properties p,\n",
    "    enwiki.user u\n",
    "WHERE \n",
    "    p.up_user = u.user_id\n",
    "    AND up_property = 'gender'\n",
    "\"\"\"\n",
    "d_gender = query_analytics_store(query, {})\n",
    "d_gender.to_csv('../../data/genders.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onionize `all_blocked_user`\n",
    "\n",
    "We want to get the k posts before and after each block event for different values of [k1, k2, ..kn]. In order for us to grow k as we please without labeling headaches, we will create a file containing the k_i-1 through k_i posts for each block event that we have not yet labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 98.8 ms\n"
     ]
    }
   ],
   "source": [
    "block_events_df = pd.read_csv('../../data/block_events.tsv', sep = \"\\t\")\n",
    "block_events_df.columns = [c.split('.')[1] for c in block_events_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.49 ms\n"
     ]
    }
   ],
   "source": [
    "nss = ['user', 'article']\n",
    "rel_path = '../../data/samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12190\n",
      "0\n",
      "1.0013580322265625e-05\n",
      "1000\n",
      "146.72958707809448\n",
      "2000\n",
      "145.94880199432373\n",
      "3000\n",
      "146.34610795974731\n",
      "4000\n",
      "147.22265601158142\n",
      "5000\n",
      "146.68694591522217\n",
      "6000\n",
      "149.18577790260315\n",
      "7000\n",
      "146.5544879436493\n",
      "8000\n",
      "147.50978899002075\n",
      "9000\n",
      "147.3107430934906\n",
      "10000\n",
      "148.7514340877533\n",
      "11000\n",
      "147.40962505340576\n",
      "12000\n",
      "150.8360137939453\n",
      "[(5, 50919), (10, 25188), (20, 35633), (30, 27717), (40, 24094), (50, 21628), (60, 19779), (70, 18399), (80, 17203), (90, 16166), (100, 15309), (150, 67494), (200, 58173), (250, 51180), (300, 45063), (500, 145860), (1000, 248597)]\n",
      "6456\n",
      "0\n",
      "8.821487426757812e-06\n",
      "1000\n",
      "142.303564786911\n",
      "2000\n",
      "142.61061596870422\n",
      "3000\n",
      "142.2872679233551\n",
      "4000\n",
      "143.64273118972778\n",
      "5000\n",
      "141.68254113197327\n",
      "6000\n",
      "145.03327083587646\n",
      "[(5, 33115), (10, 22105), (20, 34353), (30, 28441), (40, 24606), (50, 22164), (60, 20420), (70, 18997), (80, 17832), (90, 16820), (100, 16007), (150, 71386), (200, 60493), (250, 52953), (300, 46564), (500, 146053), (1000, 229950)]\n",
      "time: 47min 34s\n"
     ]
    }
   ],
   "source": [
    "for ns in nss:\n",
    "    infile = os.path.join(rel_path, ns, 'clean', 'all_blocked_user.tsv')\n",
    "    out_dir = os.path.join(rel_path, ns, 'clean', 'blocked_user_onion')\n",
    "    df = pd.read_csv(infile, sep = '\\t')\n",
    "    users = list(set(df['user_text']))\n",
    "    print(len(users))\n",
    "\n",
    "    k_prev = 0\n",
    "    ks = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250, 300, 500, 1000]\n",
    "    dfs = {k:[] for k in ks}\n",
    "\n",
    "    t1 = time.time()\n",
    "    for i, user in enumerate(users):\n",
    "        if i % 1000 ==0:\n",
    "            print (i)\n",
    "            print(time.time()-t1)\n",
    "            t1 = time.time()\n",
    "        df_user = df[df['user_text'] == user].sort_values(by='rev_timestamp')\n",
    "        if df_user.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        block_events_df_user = block_events_df[block_events_df['user_text']==user]\n",
    "        seen_ids = set()\n",
    "\n",
    "\n",
    "        for i,r in block_events_df_user.iterrows():\n",
    "            ts = r['timestamp']\n",
    "            for k in ks:\n",
    "                df_user_pre = df_user[df_user['rev_timestamp'] <= ts][-k:]\n",
    "\n",
    "                if df_user_pre.shape[0] > 0:\n",
    "                    df_user_pre = df_user_pre[df_user_pre['rev_id'].apply(lambda x: x not in seen_ids )]\n",
    "                    if df_user_pre.shape[0] > 0:\n",
    "                        seen_ids.update(tuple(df_user_pre['rev_id']))\n",
    "                        dfs[k].append(df_user_pre)\n",
    "\n",
    "                df_user_post = df_user[df_user['rev_timestamp'] > ts][:k]\n",
    "                if df_user_post.shape[0] > 0:\n",
    "                    df_user_post = df_user_post[df_user_post['rev_id'].apply(lambda x: x not in seen_ids ) ]\n",
    "                    if df_user_post.shape[0] > 0:\n",
    "                        seen_ids.update(tuple(df_user_post['rev_id']))\n",
    "                        dfs[k].append(df_user_post)\n",
    "\n",
    "    dfs = {k: pd.concat(v) for k,v in dfs.items()}\n",
    "\n",
    "    sizes = [(k, len(v)) for k,v in dfs.items()]\n",
    "    sizes.sort(key=lambda x: x[0])\n",
    "    print(sizes)\n",
    "\n",
    "\n",
    "    os.system('rm -rf %s' % out_dir)\n",
    "    os.system('mkdir  %s' % out_dir)\n",
    "\n",
    "    for k, v in dfs.items():\n",
    "        v.iloc[np.random.permutation(len(v))].to_csv(out_dir +'/%d.tsv' % k, sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
