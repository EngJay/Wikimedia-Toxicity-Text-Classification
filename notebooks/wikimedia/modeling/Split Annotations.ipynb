{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to split the set of annotated comments into fixed train,dev,test splits. The catch is that we want to ensure that a certain subset of comments labeled more than 20 times ends up in the test split. This is so that we can do a clean baselines experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellerywulczyn/miniconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/annotations/clean/annotations.tsv', sep='\\t')\n",
    "df.index = df['rev_id']\n",
    "df['counts'] = df['rev_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116179\n"
     ]
    }
   ],
   "source": [
    "df_revs = df.drop_duplicates(subset = ['rev_id'])[['rev_id', 'sample', 'counts']]\n",
    "n_revs = df_revs.shape[0]\n",
    "print(n_revs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose how many baseline revs to choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blocked    6715\n",
       "random     4285\n",
       "Name: sample, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_revs.query(\"counts >=20\")['sample'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_baseline_revs_per_sample = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create data frame of just baseline revs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_baseline_random_revs = df_revs.query(\"counts >=20 and sample == 'random'\")\\\n",
    ".sample(n=n_baseline_revs_per_sample, random_state = 12)[['rev_id']]\n",
    "\n",
    "df_baseline_blocked_revs = df_revs.query(\"counts >=20 and sample == 'blocked'\")\\\n",
    ".sample(n=n_baseline_revs_per_sample, random_state = 12)[['rev_id']]\n",
    "\n",
    "df_baseline_revs = pd.concat([df_baseline_random_revs, df_baseline_blocked_revs])\n",
    "df_baseline_revs['baseline'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create data frame of non baseline revs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108179\n"
     ]
    }
   ],
   "source": [
    "df_non_baseline_revs = df_revs[['rev_id']]\n",
    "df_non_baseline_revs = df_non_baseline_revs.merge(df_baseline_revs, how = 'left', on = 'rev_id')\n",
    "df_non_baseline_revs = df_non_baseline_revs.fillna(False)\n",
    "df_non_baseline_revs = df_non_baseline_revs.query(\"baseline == False\")[['rev_id']]\n",
    "df_baseline_revs = df_baseline_revs[['rev_id']]\n",
    "n_non_baseline_revs = df_non_baseline_revs.shape[0]\n",
    "print(n_non_baseline_revs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make 3:1:1 split, but put all baseline revs in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fraction = (0.6 * n_revs) / n_non_baseline_revs\n",
    "temp, train = train_test_split(df_non_baseline_revs, random_state = 12, test_size = train_fraction)\n",
    "dev_fraction = (0.2 * n_revs) / ((1-train_fraction) * n_non_baseline_revs)\n",
    "test, dev = train_test_split(temp, random_state = 12, test_size = dev_fraction)\n",
    "test = pd.concat([test, df_baseline_revs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69708, 1)\n",
      "(23236, 1)\n",
      "(23235, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(dev.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_train = df.merge(train, how='inner', on = 'rev_id')\n",
    "d_train.to_csv('../../data/annotations/split/train/annotations.tsv', index=False, sep='\\t')\n",
    "\n",
    "d_dev = df.merge(dev, how='inner', on = 'rev_id')\n",
    "d_dev.to_csv('../../data/annotations/split/dev/annotations.tsv', index=False, sep='\\t')\n",
    "\n",
    "d_test = df.merge(test, how='inner', on = 'rev_id')\n",
    "d_test.to_csv('../../data/annotations/split/test/annotations.tsv', index=False, sep='\\t')\n",
    "\n",
    "d_baseline = df.merge(df_baseline_revs, how='inner', on = 'rev_id')\n",
    "d_baseline.to_csv('../../data/annotations/split/baseline/annotations.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(764050, 23)\n",
      "(254449, 23)\n",
      "(350459, 23)\n",
      "(183489, 23)\n"
     ]
    }
   ],
   "source": [
    "print(d_train.shape)\n",
    "print(d_dev.shape)\n",
    "print(d_test.shape)\n",
    "print(d_baseline.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(764050, 23)\n",
      "(254449, 23)\n",
      "(350459, 23)\n",
      "(183489, 23)\n"
     ]
    }
   ],
   "source": [
    "# check numcols matched when you read in data\n",
    "print( pd.read_csv('../../data/annotations/split/train/annotations.tsv', sep='\\t').shape)\n",
    "print( pd.read_csv('../../data/annotations/split/dev/annotations.tsv', sep='\\t').shape)\n",
    "print( pd.read_csv('../../data/annotations/split/test/annotations.tsv', sep='\\t').shape)\n",
    "print( pd.read_csv('../../data/annotations/split/baseline/annotations.tsv', sep='\\t').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 45)\n",
      "(0, 45)\n",
      "(0, 45)\n",
      "(0, 45)\n",
      "(0, 45)\n"
     ]
    }
   ],
   "source": [
    "# check that splits are distinct in terms of ids\n",
    "col = 'rev_id'\n",
    "print(d_train.merge(d_dev, how = 'inner', on = col).shape)\n",
    "print(d_train.merge(d_test, how = 'inner', on = col).shape)\n",
    "print(d_test.merge(d_dev, how = 'inner', on = col).shape)\n",
    "print(d_train.merge(d_baseline, how = 'inner', on = col).shape)\n",
    "print(d_dev.merge(d_baseline, how = 'inner', on = col).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4338373, 45)\n"
     ]
    }
   ],
   "source": [
    "# check that test and baseline splits ovserlap\n",
    "print(d_test.merge(d_baseline, how = 'inner', on = col).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 45)\n",
      "(0, 45)\n",
      "(0, 45)\n"
     ]
    }
   ],
   "source": [
    "# check that splits are distinct in terms of text\n",
    "col = 'clean_diff'\n",
    "print(d_train.merge(d_dev, how = 'inner', on = col).shape)\n",
    "print(d_train.merge(d_test, how = 'inner', on = col).shape)\n",
    "print(d_test.merge(d_dev, how = 'inner', on = col).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">article</th>\n",
       "      <th>blocked</th>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>1625</td>\n",
       "      <td>1625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">user</th>\n",
       "      <th>blocked</th>\n",
       "      <td>2840</td>\n",
       "      <td>2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>2375</td>\n",
       "      <td>2375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ns  sample\n",
       "ns      sample               \n",
       "article blocked  1160    1160\n",
       "        random   1625    1625\n",
       "user    blocked  2840    2840\n",
       "        random   2375    2375"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_baseline.drop_duplicates(subset='rev_id').groupby(['ns', 'sample'])['ns', 'sample'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
