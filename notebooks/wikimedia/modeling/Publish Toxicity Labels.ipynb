{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "import data_generation.diff_utils\n",
    "import data_generation.mwdiff.mwdiffs_to_tsv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../../data/toxicity_annotations/raw/toxicity_for_ellery.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1671721, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_blocked       504821\n",
       "user_random        504800\n",
       "article_blocked    331055\n",
       "article_random     331045\n",
       "Name: query, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['query'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['ns'] = df['query'].apply(lambda x: x.split('_')[0])\n",
    "df['sample'] = df['query'].apply(lambda x: x.split('_')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make random and blocked samples disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    166415\n",
      "2       215\n",
      "Name: rev_id, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellerywulczyn/miniconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    166630\n",
      "Name: rev_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.index = df.rev_id\n",
    "df.sample_count = df.drop_duplicates(subset=['rev_id', 'sample'])['rev_id'].value_counts()\n",
    "print(df.sample_count.value_counts())\n",
    "# just set them all to random\n",
    "df['sample'][df.sample_count == 2] = 'random'\n",
    "del df.sample_count\n",
    "print(df.drop_duplicates(subset=['rev_id', 'sample'])['rev_id'].value_counts().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['toxicity'] = (df['toxicity_score'] < 0).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0    812717\n",
       " 1.0    572471\n",
       "-1.0    200512\n",
       "-2.0     45825\n",
       " 2.0     23123\n",
       "NaN      17073\n",
       "Name: toxicity_score, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxicity_score'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1425384\n",
       "1     246337\n",
       "Name: toxicity, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxicity'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove answers to test questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# annotations:  1671721\n"
     ]
    }
   ],
   "source": [
    "df = df.query('_golden == False')\n",
    "print('# annotations: ', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove annotations where revision could not be read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# annotations:  1657460\n"
     ]
    }
   ],
   "source": [
    "from baselines import remove_na\n",
    "# remove all annotations for a revisions where more than 50% of annotators for that revision could not read the comment\n",
    "df = remove_na(df)\n",
    "print('# annotations: ', df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# annotations:  1651459\n"
     ]
    }
   ],
   "source": [
    "# remove all annotations where the annotator could not read the comment\n",
    "df = df.query('na==False')\n",
    "print('# annotations: ', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure that each rev was only annotated by the same worker once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1651443\n",
       "2          8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['rev_id', '_worker_id']).size().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# annotations:  1651451\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset = ['rev_id', '_worker_id'])\n",
    "print('# annotations: ', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out annotations for revisions with  duplicated diff content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165208\n"
     ]
    }
   ],
   "source": [
    "comments = df.drop_duplicates(subset = ['rev_id'])\n",
    "print(comments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160588\n"
     ]
    }
   ],
   "source": [
    "u_comments = comments.drop_duplicates(subset = ['comment_text'])\n",
    "print(u_comments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# annotations:  1605360\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(u_comments[['rev_id']], how = 'inner', on = 'rev_id')\n",
    "print('# annotations: ', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that labels are not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0    792657\n",
       " 1.0    558147\n",
       "-1.0    190434\n",
       "-2.0     42075\n",
       " 2.0     22047\n",
       "Name: toxicity_score, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxicity_score'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1372851\n",
       "1     232509\n",
       "Name: toxicity, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxicity'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove annotations from all revisions that were annotated less than 8 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = df['rev_id'].value_counts().to_frame()\n",
    "counts.columns = ['n']\n",
    "counts['rev_id'] = counts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    154088\n",
       "9       2635\n",
       "11      2063\n",
       "8        665\n",
       "7        336\n",
       "Name: n, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts['n'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_enough = counts.query(\"n>=8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# annotations:  1601838\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(counts_enough[['rev_id']], how = 'inner', on = 'rev_id')\n",
    "print('# annotations: ', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get set of labeled comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_comments = df.drop_duplicates(subset = ['rev_id']).copy()\n",
    "df_comments['logged_in'] = df_comments['user_id'].notnull()\n",
    "df_comments['year'] = pd.to_datetime(df_comments['rev_timestamp']).apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elements = np.array([\"train\", \"dev\", \"test\"])\n",
    "probabilities = np.array([0.6, 0.2, 0.2])\n",
    "df_comments['split'] = np.random.choice(elements, size=df_comments.shape[0], p=list(probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    96334\n",
       "dev      31869\n",
       "test     31854\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments['split'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rename workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_workers = df[['_worker_id']].drop_duplicates()\n",
    "df_workers['anon_id'] = range(df_workers.shape[0])\n",
    "df = df.merge(df_workers, how = 'inner', on = '_worker_id')\n",
    "df.shape\n",
    "\n",
    "# save worker id mapping\n",
    "df_workers.to_csv(os.path.join( \"../../data/figshare\", 'toxicity_annotations_worker_id_map.tsv'), sep = '\\t', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix legacy special token issues\n",
    "\n",
    "df_comments['diff'] = df_comments['diff'].apply(data_generation.mwdiff.mwdiffs_to_tsv.replace_special_chars)\n",
    "df_comments['diff'] = df_comments['diff'].apply(lambda x: x.replace('TAB', 'TAB_TOKEN'))\n",
    "df_comments['diff'] = df_comments['diff'].apply(lambda x: x.replace('NEWLINE', 'NEWLINE_TOKEN'))\n",
    "df_comments['diff'] = df_comments['diff'].apply(lambda x: x.replace('\"', '`'))\n",
    "\n",
    "# apply latest version of clean and filter\n",
    "df_comments = data_generation.diff_utils.clean_and_filter(df_comments)\n",
    "# clean and filter drops some comments, so drop associated labels\n",
    "df = df.merge(df_comments[['rev_id']], how = 'inner', on = 'rev_id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159686, 7)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename some columns\n",
    "df_comments = df_comments.rename(columns={\n",
    "                        'clean_diff': 'comment',\n",
    "                        'rev_timestamp': 'timestamp',\n",
    "        \n",
    "                       })\n",
    "order = ['rev_id', 'comment', 'year', 'logged_in', 'ns', 'sample', 'split']\n",
    "df_comments = df_comments[order]\n",
    "df_comments = df_comments.sort_values('rev_id')\n",
    "df_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get set of human labels\n",
    "\n",
    "df_toxicity_labels = df[['rev_id', 'anon_id', 'toxicity', 'toxicity_score']]\n",
    "\n",
    "df_toxicity_labels = df_toxicity_labels.rename(columns={\n",
    "                        'anon_id': 'worker_id',\n",
    "                       })\n",
    "\n",
    "df_toxicity_labels = df_toxicity_labels.sort_values('rev_id')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save dfs\n",
    "df_comments.to_csv(os.path.join( \"../../data/figshare\", 'toxicity_annotated_comments.tsv'), sep = '\\t', index = False)\n",
    "df_toxicity_labels.to_csv(os.path.join( \"../../data/figshare\", 'toxicity_annotations.tsv'), sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159686, 7)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join( \"../../data/figshare\", 'toxicity_annotated_comments.tsv'), sep = '\\t').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159686, 4)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join( \"../../data/figshare\", 'toxicity_annotations.tsv'), sep = '\\t').drop_duplicates(subset = 'rev_id').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1315373</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223073</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480113</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099396</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941623</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rev_id                                            comment  year  \\\n",
       "1315373   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002   \n",
       "223073    4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002   \n",
       "480113    8953.0                          Elected or Electoral? JHK  2002   \n",
       "1099396  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002   \n",
       "941623   28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "        logged_in       ns  sample  split  \n",
       "1315373      True  article  random  train  \n",
       "223073       True     user  random  train  \n",
       "480113      False  article  random   test  \n",
       "1099396      True  article  random  train  \n",
       "941623       True  article  random   test  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
