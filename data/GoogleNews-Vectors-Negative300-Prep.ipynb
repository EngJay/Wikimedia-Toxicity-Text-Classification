{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "import string\n",
    "from io import BytesIO\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import msgpack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2VecKeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_embed = Word2VecKeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "vocab = {}\n",
    "vectors = [\n",
    "    np.zeros((300, ), dtype='float32'),\n",
    "]\n",
    "for word in raw_embed.vocab:  # TODO IMPROVEMENT Is checking for non-ascii like this necessary?\n",
    "    allowed = True\n",
    "    for letter in word:\n",
    "        if letter not in string.ascii_lowercase:  # TODO IMPROVEMENT Are valid ascii words that are not lowercase being rejected?\n",
    "            allowed = False  # I don't see any step to force the words to lowercase before this check.\n",
    "            break\n",
    "    if allowed:\n",
    "        vocab[word] = len(vectors)\n",
    "        vectors.append(raw_embed.vectors[raw_embed.vocab[word].index])\n",
    "# TODO IMPROVEMENT Avoid the problems of serializing numpy arrays by separating\n",
    "# the vocab from vectors.\n",
    "embed = {\n",
    "    'vocab': vocab,\n",
    "    'vectors': np.array(vectors),\n",
    "    }\n",
    "# with open(cache_filename, 'wb') as f_out:\n",
    "#     pickle.dump(embed, f_out, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleNews_word2id = embed['vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln(word2id_df): 155060\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id\n",
       "in     1\n",
       "for    2\n",
       "that   3\n",
       "is     4\n",
       "on     5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id_df = pd.DataFrame.from_dict(GoogleNews_word2id, orient='index', columns=['id'])\n",
    "print(\"ln(word2id_df):\", len(word2id_df))\n",
    "word2id_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index  id\n",
       "0    in   1\n",
       "1   for   2\n",
       "2  that   3\n",
       "3    is   4\n",
       "4    on   5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word_df = word2id_df.reset_index()\n",
    "id2word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index\n",
       "id      \n",
       "1     in\n",
       "2    for\n",
       "3   that\n",
       "4     is\n",
       "5     on"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word_df = id2word_df.set_index('id')\n",
    "id2word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of just IDs to words.\n",
    "id2word_dict = id2word_df.to_dict()\n",
    "id2word_dict = id2word_dict['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch keys/values and store word2id dictionary.\n",
    "# Needed to encode examples.\n",
    "word2id_dict = {y: x for x, y in id2word_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GoogleNews_word2id.bin', 'wb') as f:\n",
    "    msgpack.pack(word2id_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GoogleNews_id2word.bin', 'wb') as f:\n",
    "    msgpack.pack(id2word_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleNews_vectors = embed['vectors']\n",
    "np.save('GoogleNews_Embeddings', GoogleNews_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodes encoded text using the id2word dict.\n",
    "def indexes_to_text(indexes):\n",
    "    found_indexes_list = []\n",
    "    not_found_indexes_list = []\n",
    "\n",
    "    for index in indexes:\n",
    "        if id2word.get(index) is not None:\n",
    "            found_indexes_list.append(id2word_dict.get(index))\n",
    "        else:\n",
    "            not_found_indexes_list.append(index)\n",
    "\n",
    "    print('Indexes not found:', not_found_indexes_list)\n",
    "\n",
    "    return ' '.join(found_indexes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in features and labels.\n",
    "f = BytesIO(file_io.read_file_to_string('wikimedia-personal-attacks-min-6-votes-GN-Encoded-data.bin', binary_mode=True))\n",
    "data = msgpack.unpack(f, raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For keeping number of words in longest document.\n",
    "max_words = 0\n",
    "\n",
    "# Create lists to store docs and labels.\n",
    "docs = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over data to build lists of docs and labels.\n",
    "num_docs = len(data)\n",
    "for i in range(num_docs):\n",
    "#     sys.stdout.write(\"processing record %i of %i       \\r\" % (i + 1, num_docs))\n",
    "#     sys.stdout.flush()\n",
    "\n",
    "    # Get index of document.\n",
    "    doc = data[i]['idx']\n",
    "\n",
    "    # Retrieve document from saved data and cast to array.\n",
    "    doc = [item for sublist in doc for item in sublist]\n",
    "\n",
    "    # Add document to docs array.\n",
    "    docs.append(doc)\n",
    "\n",
    "    # Add label to label array at same index.\n",
    "    labels.append(data[i]['label'])\n",
    "\n",
    "    # Track maximum number of words in document.\n",
    "    if len(doc) > max_words:\n",
    "        max_words = len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115841"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also create plain text version of GN vectors for retrofitting, etc.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
